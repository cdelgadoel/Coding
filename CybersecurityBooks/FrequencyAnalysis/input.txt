En la era contemporánea del desarrollo de software, las organizaciones se enfrentan a desafíos y oportunidades en constante evolución. Este capítulo se adentra primero en el paisaje moderno, explorando la importancia de la arquitectura de microservicios, y la revolución de la contenerización. Después se reconocerá el problema que se abordará en este trabajo, el de monitorear efectivamente la arquitectura de microservicios. Finalmente, se hablará de cómo se abordará este problema, detallando la metodología a utilizar y las distintas fases que tendrá el proyecto.  

1.1	Contexto
En los últimos años, la arquitectura de microservicios ha tomado un protagonismo sin precedentes en la comunidad ingenieril. Por mucho tiempo la arquitectura monolítica fue el estándar, pero las demandas crecientes de corporaciones globales requieren de sistemas flexibles y escalables para atender a clientes dispersos geográficamente. Las aplicaciones monolíticas utilizan una única entidad indivisible, donde cada cambio o adaptación requiere una modificación completa del sistema, seguida de un nuevo despliegue de este. Esta rigidez, aunada a los tiempos de inactividad durante las actualizaciones y a la dificultad de escalar componentes individuales, resultó ser insuficiente para las grandes corporaciones. Además, la arquitectura monolítica no favorece un buen desarrollo en paralelo para organizaciones con tantos empleados. Es en este contexto que emerge la arquitectura de microservicios, ofreciendo un diseño descentralizado donde cada servicio opera de forma autónoma, pero proporcionando una experiencia integrada al usuario al estar en conjunto. Esta modularidad facilita la escalabilidad del sistema, y también facilita una mejor distribución de desarrollo, agilizando el proceso y mejorando la resiliencia del sistema en su conjunto. 

La adopción de esta nueva arquitectura trajo consigo la necesidad de administrar y orquestar de manera eficiente una gran cantidad de servicios independientes. En este contexto, la tecnología de contenedores emergió como una solución especial. Los contenedores permiten empaquetar una aplicación junto con sus dependencias, bibliotecas y configuración en una única unidad estandarizada, garantizando que la aplicación se ejecute de manera consistente en cualquier entorno. Docker, en particular, se convirtió en una herramienta revolucionaria al popularizar la contenerización, ofreciendo una plataforma que simplifica la creación, el despliegue y la ejecución de aplicaciones dentro de contenedores.

Sin embargo, a medida que las organizaciones comenzaron a adoptar contenedores a gran escala, surgió un nuevo desafío: la necesidad de administrar y orquestar múltiples contenedores de manera eficiente. Aquí es donde Kubernetes entra en escena. Desarrollado originalmente por Google y luego donado a la Cloud Native Computing Foundation (CNCF), Kubernetes es un sistema de orquestación de contenedores que permite la automatización de despliegue, escalado y operación de aplicaciones contenerizadas. Con Kubernetes, las empresas pueden gestionar clústeres de contenedores, asegurando que tengan los recursos que necesitan, recuperando contenedores o servicios en caso de fallos y facilitando la escalabilidad según la demanda. La combinación de microservicios con la tecnología de contenedores y la orquestación proporcionada por Kubernetes ha configurado una nueva era en el desarrollo y despliegue de aplicaciones. 

En una encuesta realizada por la CNCF en 2021, 96% de las empresas usan Kubernetes o piensan en usarlo (Cloud Native Computing Foundation, 2021). Grandes empresas como Google, Microsoft y Amazon ya han empezado a capitalizar este auge, implementando servicios en la nube basados en Kubernetes. Estas tres empresas desarrollaron, respectivamente, a Azure Kubernetes System (AKS), Google Kubernetes Engine (GKE), y Amazon Elastic Kubernetes Service (EKS). Pero estas soluciones no son únicas, cada vez son más las soluciones basadas en Kubernetes.  

Lo más destacado de las arquitecturas basadas en contenedores y microservicios es el desacoplamiento de las partes. Piénsese en el funcionamiento de un restaurante que tiene diferentes partes. Se tiene al equipo de cocina que se encarga de preparar alimentos, y por separado se tiene al equipo de meseros. Estos equipos son independientes el uno del otro, y proveen el servicio completo al trabajar de forma conjunta. Si hay un problema en la cocina, no se cierra todo el restaurante. Aún pueden recibirse clientes y escuchar sus demandas. En términos de software esto permite que desarrolladores puedan trabajar en sistemas distintos al mismo tiempo. También, si se necesitan más componentes de un tipo, no cambia la forma en que funcionan las otras componentes, ni el sistema en general. 

Este nuevo entorno con estas nuevas arquitecturas y componentes ofrece un abanico de ventajas competitivas para las organizaciones. La modularidad inherente a los microservicios facilita la adaptación y la innovación, permitiendo a las organizaciones responder con agilidad a las cambiantes demandas del mercado. 

Sin embargo, con estas ventajas también han surgido muchos desafíos que antes eran desconocidos o menos prevalentes en el ámbito del desarrollo de software. La fragmentación de una aplicación en múltiples servicios autónomos puede complicar el monitoreo. En particular, la detección y corrección de fallos puede volverse más desafiante en un sistema donde múltiples servicios interactúan entre sí y no se está seguro de cuál de ellos proviene el problema. Si bien el panorama actual de desarrollo proporciona herramientas y prácticas que potencian la innovación y la adaptabilidad, también demanda una renovada atención a la gestión para garantizar que las soluciones sean robustas y resilientes en este nuevo entorno dinámico.

1.2	Identificación del problema 
Una red de microservicios puede resultar muy compleja de gestionar y monitorear. En todo servicio es crítica la necesidad de mantener una visión clara de la salud y el rendimiento del sistema. En el entorno particular de las arquitecturas que involucran tantos servicios, ya no solo se necesita conocer la salud de cada servicio, sino que se vuelve fundamental poder analizar las interacciones que tienen distintos servicios. La mayoría de los problemas se originarán en un servicio, pero este error se propagará a otros y estallará finalmente en algún otro. ¿Cómo se encontrará qué servicio es el inicial? ¿De qué forma se puede abordar este problema para que demore el menor tiempo posible? 
 
Además, la complejidad de los servicios puede crecer tanto que, aunque no estalle el sistema, pueden surgir problemas ocasionados por decisiones inadecuadas de diseño. Se deben poder detectar problemas como relaciones circulares, caminos de comunicación demasiado tardados, servicios que son cruciales en el sistema y que deben de contar con más seguridad o recursos.  

Ya existen muchas herramientas que permiten monitorear las comunicaciones entre los microservicios o contenedores, como Hubble y Cilium, e incluso permiten visualizar la red de forma gráfica. El problema es que las visualizaciones no permiten hacer análisis más dinámicos o profundos de la red, solo muestran las dependencias entre los servicios. 

1.3	Objetivos 
Hay dos objetivos principales del presente trabajo. El primero es desarrollar una interfaz gráfica que permita visualizar y navegar sobre el grafo de los servicios. Este grafo pertenecerá a un intervalo específico de tiempo, y las aristas de este podrán representar distintas cosas. Esta visualización será muy útil para ganar mejor comprensión de la red y para un monitoreo más sencillo de la misma. Será sobre todo útil para investigar problemas de la red de servicios. Si un nodo tiene muchas comunicaciones fallidas, podrá investigarse la relación que tiene con los demás nodos e indagar sobre la red para ver de dónde proviene el error. 

El segundo objetivo es incorporar algoritmos de teoría de grafos para analizar la topología de la red. Estos algoritmos permitirán identificar posibles puntos de fallo o de mejora al analizar estructuras no deseadas, conjuntos de servicios que no se comunican, nodos centrales para el sistema, entre otros.  

1.4	Metodología
En este apartado se describe la metodología utilizada para desarrollar el proyecto. Para este proyecto, se utilizó la metodología en cascada. Esta se eligió porque proporciona una estructura clara y secuencial que es adecuada para proyectos individuales con requisitos bien definidos desde el inicio. La metodología en cascada permite un control riguroso y una documentación detallada de cada fase del desarrollo, lo cual es crucial para asegurar la calidad y el cumplimiento de los objetivos del proyecto.

La metodología en cascada es adecuada en este contexto por las siguientes razones:
•	Claridad de requisitos: Los objetivos y requisitos del proyecto estaban claramente definidos desde el inicio, lo que facilita la planificación y ejecución secuencial.
•	Estructura Secuencial: La metodología en cascada facilita una gestión organizada y sistemática de cada etapa del desarrollo, asegurando que todas las actividades se realicen conforme al plan establecido.
•	Control y documentación: Proporciona un marco sólido para la documentación y el control de cada fase, lo que permite un seguimiento detallado del progreso y facilita la identificación y corrección de problemas.

Las etapas seguidas en esta metodología fueron:
1.	Análisis de requisitos: Se identificaron y documentaron todos los requisitos necesarios para el desarrollo del proyecto, incluyendo los objetivos específicos y las restricciones técnicas. Esto se detalla en el capítulo dos.
2.	Diseño del sistema: Se realizó un diseño detallado de la arquitectura del sistema, incluyendo las estructuras de datos, la lógica de procesamiento y la definición de los algoritmos a implementar. Esto se detalla en el capítulo tres.
3.	Implementación: Se llevó a cabo el desarrollo del código, empleando distintas herramientas tecnológicas para la implementación de los componentes necesarios. Dento de la implementación se hicieron pruebas a la par para cersiorarse de que la solución cumpliera su propósito. Además, también se hicieron aquí los ajustes para desplegar fácilmente la herramienta. Esto se detalla en el capítulo cuatro.
4.	Pruebas: Se ejecutaron pruebas para validar el correcto funcionamiento del sistema, evaluando tanto los aspectos funcionales como los no funcionales. Esto se detalla en el capítulo cinco.
1.5	Organización del documento
En los capítulos siguientes, se estudiará de forma técnica tanto el problema en cuestión como la solución propuesta en esta tesis. El capítulo dos se enfocará en establecer los criterios que debe cumplir la solución propuesta, delineando al mismo tiempo las restricciones y el alcance de la propuesta presentada en este documento. Asimismo, se realizará una revisión comparativa de otras soluciones que se han propuesto para abordar el mismo problema, destacando las particularidades y ventajas de la solución que aquí se introduce.

El capítulo tres estará dedicado a una exposición detallada de la solución seleccionada. En este segmento, se evaluarán diversas alternativas, se justificará la opción que ha sido adoptada, y se describirá minuciosamente la arquitectura sobre la cual se construye la solución. Adicionalmente, se hará referencia a varios estándares que han guiado el diseño y la implementación, con el objetivo de evitar decisiones arbitrarias en el desarrollo del proyecto.

El capítulo cuatro abordará la metodología de implementación de la solución elegida. Este apartado detallará las tecnologías adoptadas, las herramientas empleadas y las pruebas realizadas para validar y ajustar el diseño del proyecto.

El capítulo cinco se dedicará a la exposición de las pruebas realizadas al sistema y su desempeño en ellas. Las pruebas se basarán en los requerimientos establecidos, tanto funcionales como no funcionales. Así, se podrá obtener una visión de la eficiencia de la red, así como del aspecto cualitativo de la misma. Esto permitirá reflexionar de forma crítica sobre la eficacia de la solución implementada, evaluando su impacto y su potencial.

En el capítulo seis, se presentarán las conclusiones del presente trabajo, resumiendo lo que se logró, lo que no, y se explorarán posibles extensiones y mejoras para el trabajo realizado.

Finalmente, se incluirá un capítulo dedicado a las referencias y los anexos.


 
2	Análisis del problema
En este capítulo se analiza el problema y la solución de una forma más técnica. Primero se analizarán los requerimientos que debe cumplir el trabajo, tanto funcionales como no funcionales. En ese apartado se describirán las funcionalidades que están disponibles para el usuario y el desempeño que deberán tener la solución general. Después se analizarán las restricciones que se tienen al desarrollar el trabajo, pero también el alcance de este. Finalmente, se hablará de trabajos relacionados y de cómo se diferencia el que se presenta en esta tesis. 

2.1	Requerimientos
Un requerimiento describe comportamiento que debe tener el sistema para solucionar adecuadamente un problema. Además, estos requerimientos deben ser verificables, coherentes, claramente expresados, y alcanzables. Hay requerimientos funcionales y no funcionales. Los requerimientos funcionales describen lo que debe hacer el sistema, mientras que los no funcionales detallan ámbitos como el desempeño, la seguridad, y la privacidad de la solución. A continuación, se detallan los requerimientos que debe cumplir la solución presentada. 

Requerimientos funcionales:
1.	Los usuarios verán una visualización que represente los servicios y las interacciones entre ellos. El usuario podrá elegir entre mostrar toda la red o mostrar una parte de la misma basada solo en algunos nodos seleccionados. 
2.	Los usuarios podrán especificar una banda específica de tiempo utilizando dos seleccionadores. Este tiempo se utilizará para filtrar las aristas con las que se generará el grafo. 
3.	El sistema ofrecerá una modalidad donde la red se actualice continuamente, sin que el usuario tenga que especificar la banda de tiempo. 
4.	Los usuarios podrán limitar la profundidad con la que se muestra la red desde nodos de interés (en la modalidad en la que no se muestra toda la red). Esta profundidad se refiere a qué tantos niveles de comunicación se podrán ver del nodo. Si la profundidad es uno, sólo se verán los servicios que se comunican directamente con el servicio seleccionado. Si la profundidad es dos, se verán los que se comunican directamente, y aquellos que se comunican a estos.   
5.	Los usuarios podrán eliminar servicios de la red. Esto resultará en que no se explore la red por caminos en los que se encuentre el servicio eliminado.
6.	Se asignará un valor numérico que represente información relevante a la comunicación entre dos servicios. Habrá distintos tipos de agregación disponible para cuando dos servicios se comuniquen más de una vez en el intervalo especificado.  Se podrá elegir entre tomar el valor máximo, el valor mínimo, y la suma de los valores numéricos de las distintas comunicaciones entre los servicios. También se podrá elegir el número de peticiones que hubo entre dos servicios durante ese tiempo.  
7.	Los usuarios podrán filtrar comunicaciones por el valor numérico asignado a ellas. Es decir, al mostrar la red, solo se explorarán caminos que estén dentro de un rango de valores especificados para las comunicaciones. 
8.	Las comunicaciones podrán ser representadas por líneas coloreadas basadas en el tipo de respuesta HTTP que tuvieron. 
9.	Se podrá analizar la topología de la red en el intervalo de tiempo seleccionado capturando resultados como el camino de mayor latencia, servicios cruciales para la red y redundancias.

Requerimientos no funcionales:
1.	La visualización deberá renderizarse y actualizarse en a lo más cinco segundos al agregar o eliminar cincuenta nodos. 
2.	La interfaz debe ser intuitiva y fácil de usar. 
3.	Las visualizaciones deben ser claras y comprensibles. 

2.2	Restricciones
Además de los requerimientos que delimitan la funcionalidad de la solución propuesta, es importante abordar las restricciones que podrían afectar tanto el desarrollo como la implementación del proyecto. Las restricciones son condiciones o límites predefinidos que inevitablemente modelan el proceso de diseño y ejecución. Estas pueden incluir factores como el tiempo disponible, los recursos financieros, y la tecnología existente. La comprensión de estas restricciones es fundamental para establecer un marco realista y alcanzable dentro del cual la solución debe operar.
Restricción de tiempo. Se cuenta con un tiempo limitado de aproximadamente cuatro meses para desarrollar el trabajo. Es por esta razón que no se ahondará en una visualización mucho más compleja de la red, ni se buscará incorporar una extensa variedad de análisis de la topología de la red. 

Rendimiento del hardware. El proyecto se desarrollará y probará en una MacBook Air con chip M2 (procesador CPU de 8
núcleos, GPU de 8 núcleos), 8GB de memoria. El proyecto no cuenta con presupuesto, por lo que se trabajará con la computadora con la que se cuenta. 

Datos de prueba. No se cuentan con datos de redes de casos de uso reales. Esto limitará el impacto directamente visible de la solución. Para mostrar su valor y probar su funcionamiento se utilizarán datos creados artificialmente, recurriendo tanto a datos aleatorios como no aleatorios. Se usarán redes de servicios montadas en un computador personal. Se crearán diferentes servicios y se harán comunicaciones entre ellos siguiendo ciertas distribuciones para simular tráfico real. 

Visualización limitada por el ojo humano. La visualización efectiva de los datos está limitada por la capacidad del ojo humano para discernir y procesar información. Esto limita la claridad al mostrar una gran cantidad de nodos mostrados de forma simultánea en la pantalla. 
